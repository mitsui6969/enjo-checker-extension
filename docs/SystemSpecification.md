# 炎上チェッカー　仕様書

## 1.アプリ概要

### アプリ名「炎上チェッカー🔥🔎」

#### 解決したい課題

- SNSでの不用意な発言が、意図せず「炎上」に繋がってしまうリスク。
- 文章や画像に、住所や連絡先などの個人情報が意図せず含まれてしまう個人情報漏洩のリスク。
- 「この投稿は大丈夫だろうか」という投稿前の不安や心理的負担。

#### コンセプト

**「投稿前の、賢いセーフティネット」**

Twitterへの投稿前に、AIがあなたの「門番」となって不適切な内容や個人情報が含まれていないかを自動でチェックします。ユーザーが炎上や情報漏洩のリスクを恐れることなく、安心して自己表現できる環境を提供するためのChrome拡張機能です。

- 作品情報登録フォームに送った作品概要
    
    Twitterへの投稿前に、AIがユーザーの「門番」となって不適切な内容や個人情報が含まれていないかを自動でチェックするChrome拡張機能です。
    ユーザーが意図せず炎上や情報漏洩をしてしまうリスクを恐れることなく、安心して投稿できる環境を提供します。
    

#### 操作の流れ

1. **投稿作成:** いつも通り、Twitterの投稿画面で文章を入力し、画像を選択する。
2. **AIチェック:** 標準の「投稿」ボタンが「**炎上チェック**」ボタンに変わっている。これをクリックすると、AIによる内容の解析が始まる。
3. **判定と実行:**
    - **【問題なしの場合】** ボタンが通常の「**投稿**」ボタンに戻る。クリックして投稿を完了。
    - **【問題ありの場合】** ボタンは「**炎上チェック**」のままロックされる。投稿内容を修正し、再度チェックを行う必要がある。
    または、「**このまま投稿ボタン**」で「**投稿**」ボタンに戻す

---

## 2.技術スタック

Chrome拡張機能

### フロントエンド

| 使用技術 | バージョン | 用途 |
| --- | --- | --- |
| **HTML** | - | Chrome拡張機能のUI構築 |
| **CSS** | - | Chrome拡張機能のUIデザイン |
| **JavaScript** | - | Chrome拡張機能の動作制御、API連携 |
| **React** | 19.1.1 | ポップアップUIのコンポーネントベースの構築 |
| **Vite** | 7.1.2 | 開発サーバーの起動、Reactコードのビルド |

### バックエンド

| 使用技術 | バージョン | 用途 |
| --- | --- | --- |
| **Python** |  | AIによる文章・画像解析APIの構築 |
| **Gemini** API |  | 投稿内容の炎上要素・個人情報の検知 |
| **Docker** |  | 開発・本番環境のコンテナ化 |

### その他

|  | 使用技術 | 用途 |
| --- | --- | --- |
| デプロイ | **Render** | バックエンドAPIのホスティング |
| バージョン管理 | **GitHub** | ソースコードの管理 |



---

## 3.API・エンドポイント仕様

### 3.1 はじめに

本ドキュメントは、Chrome拡張機能「炎上チェッカー🔥🔎」が使用するバックエンドAPIの仕様を定義するものです。

このAPIは、ユーザーが投稿しようとしているテキストに、炎上リスクや個人情報漏洩のリスクがないかを解析し、結果を返却する。


- データフォーマット: `JSON`
- 文字エンコーディング: `UTF-8`

### 3.2 共通仕様

- **HTTPステータスコード**
    
    
    | コード | 説明 |
    | --- | --- |
    | `200 OK` | リクエスト成功。解析結果をボディに含む。 |
    | `400 Bad Request` | リクエスト形式が不正（例: 必須パラメータの欠損） |
    | `422 Unprocessable Entity` | リクエストの形式は正しいが、内容が不正（例: Base64ではない文字列） |
    | `500 Internal Server Error` | サーバー内部でエラーが発生 |
    | `503 Service Unavailable` | 外部API（Gemini API）でエラーが発生した場合など |
- **エラーレスポンス形式**
    
    ステータスコード `4xx` または `5xx` が返却される場合、レスポンスボディは以下の形式となる。
    
    ```json
    {
      "detail": "エラー内容を示す詳細メッセージ"
    }
    ```
    

### 3.3 エンドポイント仕様

**3.3.1 投稿内容のチェック** (`/check/post`)

投稿されたテキスト内容をAIが解析し、リスクレベルとコメントを返す。

- エンドポイント: `/check/post`
- HTTPメソッド: `POST`

<br/>

**リクエスト**

| キー | 型 | 必須 | 説明 |
| --- | --- | --- | --- |
| `post` | string | ✅ | 解析対象のテキスト |

- リクエストボディ
    
    ```json
    {
    	"post": "投稿内容のテキスト"
    }
    ```
    
<br/>

**レスポンス**

| キー | 型 | 説明 |
| --- | --- | --- |
| `risk_level` | string | 炎上リスクの高さ。”high”, “middle”, “low”の3段階。 |
| `ai_comment` | string | AIからのコメント。 |

- レスポンスボディ
    
    ```json
    {
    	"risk_level": "high",
    	"ai_comment": "hogehoge"
    }
    ```

- risk_level一覧
    
    | 値 | 意味 |
    | --- | --- |
    | `low` | 問題なし |
    | `middle` | 軽微~中程度のリスクあり |
    | `high` | 高いリスクあり |
